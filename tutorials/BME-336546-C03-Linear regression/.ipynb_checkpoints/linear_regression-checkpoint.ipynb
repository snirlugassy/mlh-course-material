{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BME-336546-C03-Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, please make sure you have updated the `bm-336546` using `tutorial3.yml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical topic\n",
    "Health insurance companies pay out in the event of a health hazard to an insured party (beneficiary). In general, the higher the risk of a person getting sick or injured, the higher the monthly insurance premium (payments) are. Insurance companies need to accurately estimate risk and set premium prices accordingly. They cannot simply set the same price for all of their beneficiaries. \n",
    "\n",
    "When setting insurance premiums, the insurance companies set some \"measurable\" criteria (features in our language) and compare those criteria to costs that have already been paid out in the past (output or labels). By relating the costs to those features, they can estimate how much they can expect to pay out in the future and hence correctly set the price of future premiums. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Our dataset is composed of the following features ($ X $) and the charges ($ y $).\n",
    "\n",
    "- Age: age of primary beneficiary.\n",
    "\n",
    "- Gender: insurance contractor gender: male or a female.\n",
    "\n",
    "- BMI: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height. Objective index of body mass $[kg / m ^ 2]$ uses the ratio of height to weight, ideally 18.5 to 24.9.\n",
    "\n",
    "- Children: Number of children covered by health insurance / Number of dependents.\n",
    "\n",
    "- Smoker: Binary feature for smoking.\n",
    "\n",
    "- Region: The beneficiary's residential area in the US: northeast, southeast, southwest, northwest (maybe related to socioeconomic status).\n",
    "\n",
    "- Charges: Individual medical costs billed by health insurance.\n",
    "\n",
    "credit: https://github.com/stedy/Machine-Learning-with-R-datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main ML topic: supervised learning\n",
    "The ML topic falls into the field of supervised learning since we train a model to have a prediction based on the relations of previously \"seen\" outputs (charges) and inputs (features). At this tutorial, we would be dealing with linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our mission\n",
    "Prediction of health insurance costs based on *explanatory variables* using *linear regression* applied on different models. \\\n",
    "The model will be \"trained\" on part of the dataset which will be called `X_train` and the prediction would be applied on a hidden part of the dataset which is called `X_test`. \\\n",
    "This partition is an ML topic that would be widely covered soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory reminders\n",
    "\n",
    "\n",
    "    \n",
    "Given $ X \\in \\mathbb{R} ^{mxn_x} $ and $ y \\in \\mathbb{R}^{m} $, we look for $ w \\in \\mathbb{R} ^{n_x} $ that would minimize the following term: \n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\parallel y - \\hat{y} \\parallel^2_2 \\space = \\space \\parallel y - Xw \\parallel^2_2\n",
    "\\label{eq:mse} \\tag{1}\n",
    "\\end{equation} $$ \n",
    "\n",
    "Let's visualize some of the terms: \n",
    "\n",
    "<center><img src=\"images/lin_reg.png\"><center>\n",
    "\n",
    "This is called the *MSE* (the mean value is simply a factor of $ m $).\n",
    "Notice that we would also like to find the bias so we actually should create the following: \n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\tilde{X} = \\begin{pmatrix}\n",
    "    1 & x_{11} & x_{12} & x_{13} & \\dots  & x_{1n_x} \\\\\n",
    "    1 & x_{21} & x_{22} & x_{23} & \\dots  & x_{2n_x} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn_x}\n",
    "\\end{pmatrix} \\in \\mathbb{R} ^{mxn_{x}+1}, \\space \\tilde{w} = \\begin{pmatrix}\n",
    "b \\\\\n",
    "w\n",
    "\\end{pmatrix} \\in \\mathbb{R} ^{n_{x}+1}\n",
    "\\label{eq:rearrange mat} \\tag{2}\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "\n",
    "From now on we will use the same notations of $ X, w $ for the matrix and vector defined in equation (2). \\\n",
    "This problem is convex and thus has a single minima if our model is linear with its parameters i.e. it is possible to estimate our predictors as matrices multiplication of the feature's matrix (or mapped features) with the coefficients vector.\n",
    "The solution of this problem is given by the pseudoinverse:\n",
    "\n",
    "$$\\begin{equation}\n",
    "w = (X^{T}X)^{-1}X^{T}y\n",
    "\\label{eq:pseudo} \\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This problem can also be solved iteratively using a well known method called \"*gradient descent*\". \\\n",
    "If we define $ x^{(i)} $ to be an observation **column**, by transposing the $i^{th}$ row so that $ x^{(i)} \\in \\mathbb{R}^{n_{x}+1} $, then our cost function is defined as: \n",
    "\n",
    "$$\\begin{equation}\n",
    "J(w) = \\frac{1}{2B}\\sum\\limits_{i=1}^{B}(y^{(i)} - w^Tx^{(i)})^2 \n",
    "\\label{eq:SGD cost} \\tag{4}\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "The weights vector ($ w $) is updated in every iteration ($n$) as follows: \n",
    "\n",
    "$$\\begin{equation}\n",
    "w_{n+1} = w_n - \\alpha \\triangledown J(w_n)\n",
    "\\label{eq:SGD} \\tag{5}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In our case:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\triangledown J(w) = -\\frac{1}{B}\\sum\\limits_{i=1}^{B}(y^{(i)} - w^Tx^{(i)})x^{(i)} \n",
    "\\label{eq:SGD grad} \\tag{6}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Convergence is guaranteed if the cost function is convex and the learning rate $ (\\alpha) $ is small enough. \\\n",
    "Ideally, we would begin with large learning rates and decrease them as we get closer to convergence; however, we will not deal with that type of gradient descent for now.\n",
    "\n",
    "\n",
    "<center><img src=\"images/gradient-descent.JPG\"><center>\n",
    "\n",
    "When $ B = 1 $, the method is known as *Stochastic Gradient Descent (SGD)* and when $ 1 < B \\le m $ it is known as *Batch Gradient Descent (BGD)*.\n",
    "\n",
    "Either way, once $ w $ was \"learned\" we can have a new beneficiary with his own \"features\" $ (x_1, x_2 \\dots, x_n) $ and simply estimate the future health insurance costs by using:\n",
    "\n",
    "$$\\begin{equation}\n",
    "y = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "\\label{eq:linear estimation} \\tag{7}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/insurance.csv\")\n",
    "print(X.sample(8, random_state=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonly encountered issue: dummy coding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many medical datasets we have categorical variables. Some of them are binary (such as male/female smoker/non-smoker etc.) and some are multi-variables such as residential region. \n",
    "\n",
    "So, how should we treat those kind of explanatory variables? \\\n",
    "We can \"dummy code\" it. Basically if we have $ K $ categories, we can define $ K-1 $ explanatory variables that are binary and would indicate the $ k^{th} $ category existence with the code $ 1 $.\n",
    "\n",
    "For more information please address: https://www.statisticssolutions.com/dummy-coding-the-how-and-why/\n",
    "\n",
    "Fortunately, *pandas* has this function built in for categorical variables denoted as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data=X, drop_first=True)\n",
    "print(X.sample(8, random_state=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the summary statistics. Print it using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/1.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the distribution (using histograms) of every variable in our data. Make sure they are clearly visible by adjusting `figsize`. \\\n",
    "Don't forget to label X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/2.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the correlation between *age* and *charges* using a scatter plot. Don't forget to put labels, units and legend as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/4.PNG\" width=\"430\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *What does the figure tell us? Does the trend of the data make sense to you?*\n",
    "\n",
    "---\n",
    "\n",
    "We can notice from the figure that there are at least two \"groups (modes)\" in our data. \\\n",
    "Can you point out which of the explanatory variables is probably the cause of these modes for some beneficiaries? \\\n",
    "Visualize your suggestion. Add labels. The labels in the expected output was hidden on purpose.\n",
    "\n",
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *Which explanatory variable corresponds with what group?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/5.PNG\" width=\"430\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same suspected explanatory variable on charges vs bmi instead of age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/6.PNG\" width=\"430\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, if we assume linear model, we can use the correlation matrix to visualize the correlation between all the categories. \\\n",
    "Use `sns.heatmap` and `X.corr()` for the visualization of the correlations. \\\n",
    "Again, make sure all of the variables' correlations and names are clearly seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Implement your code here-------------------\n",
    "\n",
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/7.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *What can you tell about the importance of each variable in the aspect of costs? Does it make sense to you?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific task:\n",
    "OK, now for the learning part.<br><br>\n",
    "Apply linear regression of beneficiary's \"features\" and his/her insurance's costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data will be divided now to input and output $ (X, y) $ and we will add the bias elements. Then we will divide our set into training and testing sets. \\\n",
    "**You should implement the closed form of the solution** (using only `numpy`, eq. 3 and eq. 7) on the training set and finally plot the prediction on both the test set (`y_pred_test`) and the trainig set (`y_pred_train`) on top of the adequate ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y = X['charges']\n",
    "X.drop(columns='charges', inplace=True)\n",
    "X = X.to_numpy() # can also be X.values\n",
    "y = y.to_numpy() # can also be y.values\n",
    "X = np.concatenate((np.ones((len(y), 1)), X), axis=1) # add bias term\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here-------------------------\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train, y_pred_test] # predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gt_vs_pred(gt_array, pred_array):\n",
    "    title =['Train', 'Train', 'Test', 'Test']\n",
    "    plot_vars = [(gt_array[0], pred_array[0]), (gt_array[1], pred_array[1])]\n",
    "    fig, axes = plt.subplots(2,2, figsize=(15,11))\n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        gt, pred = plot_vars[idx>=2]\n",
    "        if np.mod(idx, 2) == 0:\n",
    "            ax.scatter(np.arange(len(gt)), gt, label='ground truth')\n",
    "            ax.scatter(np.arange(len(gt)), pred, label='prediction')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('# of beneficiary')\n",
    "            ax.set_ylabel('Charges [$]')\n",
    "            ax.set_title(title[idx])\n",
    "        else:        \n",
    "            sns.histplot(gt - pred, ax=ax, kde=True, fill=True, alpha=0.3, linewidth=0)\n",
    "            ax.set_title(title[idx])\n",
    "            ax.set_xlabel('ground truth - prediction')\n",
    "            ax.set_ylabel('pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gt_vs_pred(gt_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/8.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *What can you tell about the performance of the regression?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please stop here and address the TA before you continue**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we will try to implement the same estimation but with sequential learning (gradient descent).\n",
    "\n",
    "**First, it is very important to standardize the data because SGD is very sensitive to large variations of the gradient that can be induced due to the values of the dataset.** \\\n",
    "Use `StandardScaler` function in order to do so and pay close attention to what should you scale and what you shouldn't. Notice that scaling **after** dividing into train and test sets avoids information leakage.\n",
    "\n",
    "\n",
    "Implement the correct standardization on the training and testing sets. **The scaled matrices or vectors names should be the same as previous scaling.** Pay close attention to which variables scaling should be applied and how to standardize the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#--------------Implement your code here-------------------------\n",
    "\n",
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement SGD and plot the MSE as a function of the iterations (learning curve in general) for both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "\n",
    "w1 = np.random.randn(X_train.shape[1])  # random initialization\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "for x_i, y_i in zip(X_train, y_train): # x_i is an observation and y_i is the adequate output\n",
    "    #--------------Implement your code here-------------------------\n",
    "\n",
    "    #---------------------------------------------------------------\n",
    "plt.plot(np.arange(len(mse_train)), mse_train)\n",
    "plt.plot(np.arange(len(mse_test)), mse_test)\n",
    "plt.legend((\"train\", \"test\"))\n",
    "plt.xlabel(\"iteration #\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/9.PNG\" width=\"450\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *Did you expect the result you got? What happens if $ \\alpha $ is too large? Try it!*\n",
    "\n",
    "---\n",
    "\n",
    "After you saw the effect it causes, set the learning rate back to normal and run the SGD again before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train, y_pred_test] # predictions\n",
    "plot_gt_vs_pred(gt_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/10.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "All we did until now can be very easily implemented using a powerful machine learning package of Python that we already used briefly and we will use it a lot in this course:  `scikit-learn` or simply `sklearn`. Look at the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) of linear regression class and try to implement the linear regression using this package that was already imported at the top on the scaled dataset. Notice that your data already has a column of ones. What argument of `LinearRegression` should you change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here-------------------------\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train, y_pred_test] # predictions\n",
    "plot_gt_vs_pred(gt_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/11.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *Did you get any better with scaling?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Linear regression of a polynomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that now we have a different dataset with a model that claims we should only use the variables of age and bmi, and we denote them as $ (x_1,x_2) $. The charges should be estimated as follows:\n",
    "\n",
    "$$\\begin{equation}\n",
    "y = w_0 + w_1x_1x_2 + w_2x_2^2\n",
    "\\label{eq:poly} \\tag{8}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We should notice that though the output is not a linear function of the features in the feature domain, it is **still linear with its parameters.** Thus we can look at the \"mapped features\" (feature that have gone through some transformation) and solve the problem as a linear regression problem in the new domain. Our \"new features\" and weights would be:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\tilde{X} = \\begin{pmatrix}\n",
    "    1 & x_{11}x_{12} & x_{12}^2 \\\\ \n",
    "    1 & x_{21}x_{22} & x_{22}^2 \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    1 & x_{m1}x_{m2} & x_{m2}^2\n",
    "\\end{pmatrix}, \\space \\tilde{w} = \\begin{pmatrix}\n",
    "w_0\\\\\n",
    "w_1\\\\\n",
    "w_2\n",
    "\\end{pmatrix}\n",
    "\\label{eq:feat transform} \\tag{9}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this case, the maximum order of the polynomial is 2. We will use the `PolynomialFeatures` class of `scikit-learn` for this task. We will also use different dataset that contains only two features.\n",
    "Let's load the new data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_data = np.load(\"data/pol_data.npz\")\n",
    "# preprocess after load\n",
    "X_new = np.c_[pol_data['x1'].ravel(), pol_data['x2'].ravel()]\n",
    "y = pol_data['data'].flatten()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should try and fit a linear model to the features. Fit your model upon the **unscaled** features and plot the results using `plot_gt_vs_pred` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here-------------------------\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train_lin, y_pred_test_lin] # predictions\n",
    "plot_gt_vs_pred(gt_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/12.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *What can you tell on the performance of the linear regression in the original domain?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the fitting process using the function `plot_lin` upon the testing set next to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lin(pol_data, x_y_axis, y_test, lin_reg):\n",
    "    x1 = pol_data['x1']\n",
    "    x2 = pol_data['x2']\n",
    "    z = pol_data['z']\n",
    "    data = pol_data['data']\n",
    "    fig = plt.figure(figsize = (16, 10))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax.plot_surface(x1, x2, z, cmap=cm.coolwarm,\n",
    "                            linewidth=0, antialiased=False, alpha=0.5)\n",
    "    R = np.random.randint(0, z.shape[0]*z.shape[1], (100,))\n",
    "    ax.scatter(x1.flatten()[R], x2.flatten()[R], data.flatten()[R])\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    ax.set_zlabel('$y$')\n",
    "    ax.view_init(elev=10, azim=140)\n",
    "    ax.set_title('Original')\n",
    "    \n",
    "    x1, x2 = np.meshgrid(np.sort(x_y_axis[:,0]), np.sort(x_y_axis[:,1]))\n",
    "    z = lin_reg.intercept_ + lin_reg.coef_[0]*x1 + lin_reg.coef_[1]*x2\n",
    "    R = np.random.randint(0, y_test.shape[0], (100,))\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax.plot_surface(x1, x2, z, cmap=cm.coolwarm,\n",
    "                            linewidth=0, antialiased=False, alpha=0.5)\n",
    "#     y_test = y_test[np.argsort(x1)]\n",
    "    ax.scatter(x_y_axis[:,0].flatten()[R], x_y_axis[:,1].flatten()[R], y_test.flatten()[R])\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    ax.set_zlabel('$y$')\n",
    "    ax.view_init(elev=10, azim=140)\n",
    "    ax.set_title('Linear fit in feature domain')\n",
    "    ax.set_zlim(0, 200)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lin(pol_data,X_test, y_test, lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/13.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see clearly that the data is not linear with the features. We should probably try a *polynomial* model. Fortunately, we can still use linear regression but we will have to apply it on the *transformed features*. Find out more about transforming features [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here:-------------------------\n",
    "\n",
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit a linear regression model to the transformed features and plot the distributions using `plot_gt_vs_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here:-------------------------\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train_pol, y_pred_test_pol] # predictions\n",
    "plot_gt_vs_pred(gt_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/14.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are now much better. The distribution of the error is Gaussian which is exactly appropriate for our assumptions about the additive noise of the data. Print the coefficients of the model and choose the indices of the two most (and basically only) significant coefficients. Make them as a list called `rel_indices`. Choose the correct `x_label` and `y_label`. Use `LaTeX` as needed. The correct labels are hidden in the expected output on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Implement your code here:-------------------------\n",
    "\n",
    "#----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the results in the transformed feature domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pol(pol_data, rel_x_y_axis, y_test, lin_reg, rel_indices,x_label,y_label):\n",
    "    x1 = pol_data['x1']\n",
    "    x2 = pol_data['x2']\n",
    "    z = pol_data['z']\n",
    "    data = pol_data['data']\n",
    "    fig = plt.figure(figsize = (16, 10))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax.plot_surface(x1, x2, z, cmap=cm.coolwarm,\n",
    "                            linewidth=0, antialiased=False, alpha=0.5)\n",
    "    R = np.random.randint(0, z.shape[0]*z.shape[1], (100,))\n",
    "    ax.scatter(x1.flatten()[R], x2.flatten()[R], data.flatten()[R])\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    ax.set_zlabel('$y$')\n",
    "    ax.view_init(elev=10, azim=140)\n",
    "    ax.set_title('Original')\n",
    "    \n",
    "    x1, x2 = np.meshgrid(np.sort(rel_x_y_axis[:,0]), np.sort(rel_x_y_axis[:,1]))\n",
    "    z = lin_reg.coef_[0] + x1*lin_reg.coef_[rel_indices[0]] + x2*lin_reg.coef_[rel_indices[1]]\n",
    "    R = np.random.randint(0, y_test.shape[0], (100,))\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "    ax.plot_surface(x1, x2, z, cmap=cm.coolwarm,\n",
    "                            linewidth=0, antialiased=False, alpha=0.5)\n",
    "    ax.scatter(rel_x_y_axis[:,0].flatten()[R], rel_x_y_axis[:,1].flatten()[R], y_test.flatten()[R])\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    ax.set_zlabel('$y$')\n",
    "    ax.view_init(elev=10, azim=125)\n",
    "    ax.set_title('Linear fit in transformed feature domain')\n",
    "    ax.set_xlim3d(-100, 100)\n",
    "    ax.set_ylim3d(0, 100)\n",
    "    ax.set_zlim3d(0, 200)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pol(pol_data, rel_x, y_test, lin_reg, rel_indices, x_label, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "<center><img src=\"outputs/15.PNG\" width=\"480\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see an important concept in machine learning: We don't always have to fit a non-linear model to our data but rather apply a non-linear transform to the features and then fit a linear model. The data can be linearized in a different domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage in healthcare and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this tutorial we saw how to implement linear regression in several ways: \n",
    ">- Pseudoinverse \n",
    ">- SGD \n",
    ">- scikit-learn (that uses either one of them)\n",
    "\n",
    "##### We noticed how sensitive SGD is to the learning rate and standardization.\n",
    "##### The use of linear regression to predict health insurance costs (and by that estimate correctly the beneficiary's insurance premiums later on). \n",
    "##### We also saw how linear regression can be fitted to some other models rather than linear ones using features transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images credit:\n",
    "\n",
    "\n",
    "[Linear regression](https://www.quora.com/q/qyczkaxdbcglctzy/The-Inception-of-a-Data-Scientist-Linear-Regression)\n",
    "\n",
    "\n",
    "[Cost function](https://saugatbhattarai.com.np/what-is-gradient-descent-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *This tutorial was written by [Moran Davoodi](mailto:morandavoodi@gmail.com) with the assitance of [Yuval Ben Sason](mailto:yuvalbse@gmail.com) & Kevin Kotzen*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
